{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aksha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the model architecture\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # Adjust num_labels as needed\n",
    "model.load_state_dict(torch.load('path to fine-tuned bert model', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prediction function\n",
    "def predict_email(text, model, tokenizer, max_len=128):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    input_ids = torch.tensor(inputs['input_ids']).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.tensor(inputs['attention_mask']).unsqueeze(0).to(device)\n",
    "    token_type_ids = torch.tensor(inputs['token_type_ids']).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "email_text = ''' put your email text here '''\n",
    "prediction = predict_email(email_text, model, tokenizer)\n",
    "print(f\"Predicted label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text, tokenizer, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    input_ids = torch.tensor(inputs['input_ids']).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.tensor(inputs['attention_mask']).unsqueeze(0).to(device)\n",
    "    token_type_ids = torch.tensor(inputs['token_type_ids']).unsqueeze(0).to(device)\n",
    "    return input_ids, attention_mask, token_type_ids\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load your dataset\n",
    "dataset = pd.read_csv(r\"cleaned_dataset.csv\")\n",
    "\n",
    "# Map email types to numerical labels\n",
    "label_mapping = {'Safe Email': 0, 'Phishing Email': 1}\n",
    "dataset['label'] = dataset['Email Type'].map(label_mapping)\n",
    "\n",
    "# Remove rows with null values in 'Email Text' column\n",
    "dataset = dataset.dropna(subset=['Email Text'])\n",
    "\n",
    "# Checkpointing\n",
    "checkpoint_path = r'progress_checkpoint.csv'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    progress_df = pd.read_csv(checkpoint_path)\n",
    "    start_index = len(progress_df)\n",
    "    true_labels = progress_df['true_labels'].tolist()\n",
    "    pred_labels = progress_df['pred_labels'].tolist()\n",
    "else:\n",
    "    start_index = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    progress_df = pd.DataFrame(columns=['true_labels', 'pred_labels'])\n",
    "\n",
    "# Check if start_index exceeds dataset length\n",
    "if start_index >= len(dataset):\n",
    "    print(\"Checkpoint indicates all data processed.\")\n",
    "else:\n",
    "    print(f\"Resuming from index: {start_index}\")\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, row in enumerate(dataset.iterrows(), start=start_index):\n",
    "        print(f\"Index: {idx}, Dataset Length: {len(dataset)}\")  # Debugging print\n",
    "        if idx >= len(dataset):\n",
    "            break  # Ensure the loop doesn't exceed the dataset length\n",
    "    # for idx, row in enumerate(dataset.iterrows(), start=start_index):\n",
    "        index, row = row\n",
    "        text = row['Email Text']\n",
    "        true_label = row['label']\n",
    "        input_ids, attention_mask, token_type_ids = preprocess_text(text, tokenizer)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(prediction)\n",
    "\n",
    "        # Save progress\n",
    "        new_row = pd.DataFrame({'true_labels': [true_label], 'pred_labels': [prediction]})\n",
    "        progress_df = pd.concat([progress_df, new_row], ignore_index=True)\n",
    "        \n",
    "        if idx % 100 == 0:  # Save every 100 steps\n",
    "            progress_df.to_csv(checkpoint_path, index=False)\n",
    "            print(f'Processed {idx + 1} / {len(dataset)}')\n",
    "\n",
    "# Final save\n",
    "progress_df.to_csv(checkpoint_path, index=False)\n",
    "\n",
    "# Remove NaN values from true_labels and pred_labels\n",
    "cleaned_df = progress_df.dropna()\n",
    "true_labels = cleaned_df['true_labels'].tolist()\n",
    "pred_labels = cleaned_df['pred_labels'].tolist()\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Optional: Convert confusion matrix to a DataFrame for better visualization\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['True_Safe', 'True_Phishing'], columns=['Pred_Safe', 'Pred_Phishing'])\n",
    "print(conf_matrix_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
